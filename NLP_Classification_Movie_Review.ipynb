{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "import glob\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='/home/ubuntu/nltk_data/corpora/movie_reviews/neg' # use your path\n",
    "allFiles = glob.glob(path + \"/*.txt\")\n",
    "frame = pd.DataFrame()\n",
    "list_ = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_table(file_, header=None)\n",
    "    list_.append(df)\n",
    "frame = pd.concat(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame['label']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame=frame.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r'/home/ubuntu/nltk_data/corpora/movie_reviews/pos' # use your path\n",
    "allFiles = glob.glob(path + \"/*.txt\")\n",
    "frame2 = pd.DataFrame()\n",
    "list_ = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_table(file_, header=None)\n",
    "    list_.append(df)\n",
    "frame2 = pd.concat(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2['label']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame2=frame2.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data=frame.append(frame2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64720, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text_nopunct\n",
    "\n",
    "final_data['body_text_clean'] = final_data[0].apply(lambda x: remove_punct(x))\n",
    "\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.rename(columns={0:'text'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    text = \"\".join([word for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [wn.lemmatize(word) for word in tokens if word not in stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s=clean_text(final_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>when true crime opts for a high-speed chase to the governer's house at the finale , the quality ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>eastwood was so successful with colorful character portraits that he didn't need to switch lanes .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>true crime is a tension-building , intriguing drama showcase for the talented director and star .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>this is a road block he could have easily dismissed ( i furrow my brow ) .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   text  \\\n",
       "19  when true crime opts for a high-speed chase to the governer's house at the finale , the quality ...   \n",
       "20  eastwood was so successful with colorful character portraits that he didn't need to switch lanes .    \n",
       "21   true crime is a tension-building , intriguing drama showcase for the talented director and star .    \n",
       "22                          this is a road block he could have easily dismissed ( i furrow my brow ) .    \n",
       "23                                               . . . . . . . . . . . . . . . . . . . . . . . . . . .    \n",
       "\n",
       "    label  \n",
       "19      1  \n",
       "20      1  \n",
       "21      1  \n",
       "22      1  \n",
       "23      1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_text(df, text_field):\n",
    "    df[text_field] = df[text_field].str.replace(r\"http\\S+\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"http\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"@\\S+\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]\", \" \")\n",
    "    df[text_field] = df[text_field].str.replace(r\"@\", \"at\")\n",
    "    df[text_field] = df[text_field].str.lower()\n",
    "    df[text_field] = df[text_field].str.replace('\\s+', ' ')\n",
    "    df[text_field] = df[text_field].str.replace(\"\\'\", \"\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = standardize_text(final_data, \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>it's a quick , straight shot to the movie's end</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>in terms of overall quality , i would compare the truman show to niccol's gattaca</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>both films are well made with interesting stories set in interesting worlds</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>but neither film really felt like it capitalized on all the great ideas   neither film \" clicked...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>nevertheless , i look forward to niccol's next film , whatever it may be</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   text  \\\n",
       "56                                                   it's a quick , straight shot to the movie's end      \n",
       "57                 in terms of overall quality , i would compare the truman show to niccol's gattaca      \n",
       "58                       both films are well made with interesting stories set in interesting worlds      \n",
       "59  but neither film really felt like it capitalized on all the great ideas   neither film \" clicked...   \n",
       "60                          nevertheless , i look forward to niccol's next film , whatever it may be      \n",
       "\n",
       "    label  \n",
       "56      1  \n",
       "57      1  \n",
       "58      1  \n",
       "59      1  \n",
       "60      1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_data[['text']], final_data['label'], test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer,HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "tfidf_vect_fit = tfidf_vect.fit(X_train['text'])\n",
    "tfidf_train = tfidf_vect_fit.transform(X_train['text'])\n",
    "tfidf_test = tfidf_vect_fit.transform(X_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hv=HashingVectorizer(analyzer=clean_text,n_features=25000 ,non_negative=True,ngram_range=(2,2))\n",
    "# x_train_hv=hv.transform(X_train['text'])\n",
    "# x_train_hv_vec=pd.DataFrame(x_train_hv.toarray())\n",
    "# x_test_hv=hv.transform(X_test['text'])\n",
    "# x_test_hv_vec=pd.DataFrame(x_test_hv.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_vect =pd.DataFrame(tfidf_train.toarray())\n",
    "# X_test_vect =pd.DataFrame(tfidf_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.68      0.69      6365\n",
      "          1       0.70      0.73      0.71      6579\n",
      "\n",
      "avg / total       0.70      0.70      0.70     12944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(tfidf_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(tfidf_test)\n",
    "#y_real_pred = classifier.predict(X_test_vect)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.62      0.64      6365\n",
      "          1       0.65      0.68      0.66      6579\n",
      "\n",
      "avg / total       0.65      0.65      0.65     12944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier(n_estimators=150, max_depth=3, n_jobs=-1)\n",
    "model=rf.fit(tfidf_train, y_train)\n",
    "pred=model.predict(tfidf_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf = RandomForestClassifier()\n",
    "# param = {'n_estimators': [10, 150, 300],\n",
    "#         'max_depth': [30, 60, 90, None]}\n",
    "\n",
    "# gs = GridSearchCV(rf, param, cv=5, n_jobs=-1)\n",
    "# gs_fit = gs.fit(tfidf_train, y_train)\n",
    "# pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text,ngram_range=(2,2))\n",
    "tfidf_vect_fit = tfidf_vect.fit(X_train['text'])\n",
    "tfidf_train = tfidf_vect_fit.transform(X_train['text'])\n",
    "tfidf_test = tfidf_vect_fit.transform(X_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.68      0.69      6365\n",
      "          1       0.70      0.73      0.71      6579\n",
      "\n",
      "avg / total       0.70      0.70      0.70     12944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(tfidf_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(tfidf_test)\n",
    "#y_real_pred = classifier.predict(X_test_vect)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.04      0.08      6365\n",
      "          1       0.52      0.99      0.68      6579\n",
      "\n",
      "avg / total       0.67      0.52      0.38     12944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier(n_estimators=150, max_depth=3, n_jobs=-1)\n",
    "model=rf.fit(tfidf_train, y_train)\n",
    "pred=model.predict(tfidf_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_tfidf = LogisticRegression(C=30.0, class_weight='balanced', solver='newton-cg', n_jobs=-1, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.68      0.68      6365\n",
      "          1       0.69      0.68      0.69      6579\n",
      "\n",
      "avg / total       0.68      0.68      0.68     12944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=clf_tfidf.fit(tfidf_train, y_train)\n",
    "pred=model.predict(tfidf_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_new = ['This movie was excellent', 'Absolute joy ride', \n",
    "            'Adam was terrible', 'Meryl shined through.', 'wasted my money','i was better at home','rocking!!',\n",
    "              'This was certainly a movie', 'Two thumbs up', 'I fell asleep halfway through', 'first half was good..second half was boring',\n",
    "              \"We can't wait for the sequel!!\", '!', '?', 'I cannot recommend this highly enough', ':-D',':-(',';-(',':-X',\n",
    "              'instant classic.', 'Brad Pitt was amazing. His performance was Oscar-worthy.','this movie is so bad, i ran away','amazing']\n",
    "\n",
    "#hash_vect_sample = TfidfVectorizer(analyzer=clean_text ,ngram_range=(2,2))\n",
    "test = tfidf_vect_fit.transform(reviews_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred=model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_pred)=pd.DataFrame(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred.rename(columns={0:'label'},inplace=True)\n",
    "test_pred['label']=np.where(test_pred['label']==0,'neg','pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'This movie was excellent' => pos\n",
      "'Absolute joy ride' => pos\n",
      "'Adam was terrible' => neg\n",
      "'Meryl shined through.' => pos\n",
      "'wasted my money' => neg\n",
      "'i was better at home' => neg\n",
      "'rocking!!' => pos\n",
      "'This was certainly a movie' => neg\n",
      "'Two thumbs up' => neg\n",
      "'I fell asleep halfway through' => neg\n",
      "'first half was good..second half was boring' => neg\n",
      "\"We can't wait for the sequel!!\" => neg\n",
      "'!' => neg\n",
      "'?' => neg\n",
      "'I cannot recommend this highly enough' => pos\n",
      "':-D' => pos\n",
      "':-(' => neg\n",
      "';-(' => neg\n",
      "':-X' => pos\n",
      "'instant classic.' => pos\n",
      "'Brad Pitt was amazing. His performance was Oscar-worthy.' => pos\n",
      "'this movie is so bad, i ran away' => neg\n",
      "'amazing' => pos\n"
     ]
    }
   ],
   "source": [
    "# naive bayes\n",
    "for review, category in zip(reviews_new, test_pred['label']):\n",
    "    print('%r => %s' % (review, category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'This movie was excellent' => pos\n",
      "'Absolute joy ride' => pos\n",
      "'Adam was terrible' => neg\n",
      "'Meryl shined through.' => neg\n",
      "'wasted my money' => neg\n",
      "'i was better at home' => neg\n",
      "'rocking!!' => pos\n",
      "'This was certainly a movie' => neg\n",
      "'Two thumbs up' => neg\n",
      "'I fell asleep halfway through' => neg\n",
      "'first half was good..second half was boring' => neg\n",
      "\"We can't wait for the sequel!!\" => neg\n",
      "'!' => neg\n",
      "'?' => neg\n",
      "'I cannot recommend this highly enough' => pos\n",
      "':-D' => neg\n",
      "':-(' => neg\n",
      "';-(' => neg\n",
      "':-X' => neg\n",
      "'instant classic.' => pos\n",
      "'Brad Pitt was amazing. His performance was Oscar-worthy.' => pos\n",
      "'this movie is so bad, i ran away' => neg\n",
      "'amazing' => pos\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "for review, category in zip(reviews_new, test_pred['label']):\n",
    "    print('%r => %s' % (review, category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_params = {'max_depth': np.arange(3,12,2), 'min_child_weight': [1,3,5]}\n",
    "# ind_params = {'learning_rate': 0.1, 'n_estimators': 1000, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "#              'objective': 'binary:logistic'}\n",
    "# optimized_GBM = GridSearchCV(xgb.XGBClassifier(**ind_params), \n",
    "#                             cv_params, \n",
    "#                              scoring = 'accuracy', cv = 5, n_jobs = -1) \n",
    "# # Optimize for accuracy since that is the metric used in the Adult Data Set notation\n",
    "# optimized_GBM.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_GBM.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
