{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=50.0,\n",
       "             max_doc_update_iter=100, max_iter=5, mean_change_tol=0.001,\n",
       "             n_components=10, n_jobs=1, n_topics=None, perp_tol=0.1,\n",
       "             random_state=0, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Initialize variables\n",
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_topics = 10\n",
    "\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1,\n",
    "                             remove=('headers', 'footers', 'quotes'))\n",
    "data_samples = dataset.data[:n_samples]\n",
    "\n",
    "# use tf feature for LDA model\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=n_features,\n",
    "                                stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(data_samples)\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, max_iter=5,\n",
    "                                learning_method='online', learning_offset=50.,\n",
    "                                random_state=0)\n",
    "lda.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.44893409e-03,   6.28598196e-01,   3.44908103e-03, ...,\n",
       "          3.44868917e-03,   3.44943514e-03,   3.44884274e-03],\n",
       "       [  3.33391110e-03,   3.33467317e-03,   9.69993827e-01, ...,\n",
       "          3.33448122e-03,   3.33413230e-03,   3.33356505e-03],\n",
       "       [  3.03086351e-03,   6.71061551e-01,   3.03059022e-03, ...,\n",
       "          3.03054785e-03,   3.03076742e-03,   3.03062719e-03],\n",
       "       ..., \n",
       "       [  2.08357969e-03,   8.84390569e-02,   2.08344836e-03, ...,\n",
       "          2.08376930e-03,   2.08360955e-03,   2.08370167e-03],\n",
       "       [  6.53656983e-04,   6.53705973e-04,   6.53712556e-04, ...,\n",
       "          6.53665594e-04,   7.88066707e-01,   6.53729463e-04],\n",
       "       [  2.00001102e-02,   2.00062768e-02,   2.21624245e-01, ...,\n",
       "          2.00018814e-02,   6.18358729e-01,   2.00023251e-02]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshat\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words=10):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print (\"Topic %d:\" % (topic_idx))\n",
    "        print (\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "edu com mail send graphics ftp pub available contact university\n",
      "Topic 1:\n",
      "don like just know think ve way use right good\n",
      "Topic 2:\n",
      "christian think atheism faith pittsburgh new bible radio games alt\n",
      "Topic 3:\n",
      "drive disk windows thanks use card drives hard version pc\n",
      "Topic 4:\n",
      "hiv health aids disease april medical care research 1993 light\n",
      "Topic 5:\n",
      "god people does just good don jesus say israel way\n",
      "Topic 6:\n",
      "55 10 11 18 15 team game 19 period play\n",
      "Topic 7:\n",
      "car year just cars new engine like bike good oil\n",
      "Topic 8:\n",
      "people said did just didn know time like went think\n",
      "Topic 9:\n",
      "key space law government public use encryption earth section security\n"
     ]
    }
   ],
   "source": [
    "display_topics(lda, tf_vectorizer.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc1 = \"Sugar is bad to consume. My sister likes to have sugar, but not my father.\"\n",
    "doc2 = \"My father spends a lot of time driving my sister around to dance practice.\"\n",
    "doc3 = \"Doctors suggest that driving may cause increased stress and blood pressure.\"\n",
    "doc4 = \"Sometimes I feel pressure to perform well at school, but my father never seems to drive my sister to do better.\"\n",
    "doc5 = \"Health experts say that Sugar is not good for your lifestyle.\"\n",
    "\n",
    "# compile documents\n",
    "doc_complete = [doc1, doc2, doc3, doc4, doc5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_text(df, text_field):\n",
    "    df[text_field] = df[text_field].str.replace(r\"http\\S+\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"http\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"@\\S+\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]\", \" \")\n",
    "    df[text_field] = df[text_field].str.replace(r\"@\", \"at\")\n",
    "    df[text_field] = df[text_field].str.lower()\n",
    "    df[text_field] = df[text_field].str.replace('\\s+', ' ')\n",
    "    df[text_field] = df[text_field].str.replace(\"\\'\", \"\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(doc_complete,columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=standardize_text(data,'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sugar is bad to consume  my sister likes to ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my father spends a lot of time driving my sist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doctors suggest that driving may cause increas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sometimes i feel pressure to perform well at s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>health experts say that sugar is not good for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  sugar is bad to consume  my sister likes to ha...\n",
       "1  my father spends a lot of time driving my sist...\n",
       "2  doctors suggest that driving may cause increas...\n",
       "3  sometimes i feel pressure to perform well at s...\n",
       "4  health experts say that sugar is not good for ..."
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize,WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords=nltk.corpus.stopwords.words('english')\n",
    "wn=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = \"\".join([word for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [wn.lemmatize(word) for word in tokens if word not in stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['body_text_clean'] = data['text'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string,re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>body_text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sugar is bad to consume  my sister likes to ha...</td>\n",
       "      <td>[sugar, bad, consume, sister, like, sugar, fat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my father spends a lot of time driving my sist...</td>\n",
       "      <td>[father, spends, lot, time, driving, sister, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doctors suggest that driving may cause increas...</td>\n",
       "      <td>[doctor, suggest, driving, may, cause, increas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sometimes i feel pressure to perform well at s...</td>\n",
       "      <td>[sometimes, feel, pressure, perform, well, sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>health experts say that sugar is not good for ...</td>\n",
       "      <td>[health, expert, say, sugar, good, lifestyle, ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  sugar is bad to consume  my sister likes to ha...   \n",
       "1  my father spends a lot of time driving my sist...   \n",
       "2  doctors suggest that driving may cause increas...   \n",
       "3  sometimes i feel pressure to perform well at s...   \n",
       "4  health experts say that sugar is not good for ...   \n",
       "\n",
       "                                     body_text_clean  \n",
       "0  [sugar, bad, consume, sister, like, sugar, fat...  \n",
       "1  [father, spends, lot, time, driving, sister, a...  \n",
       "2  [doctor, suggest, driving, may, cause, increas...  \n",
       "3  [sometimes, feel, pressure, perform, well, sch...  \n",
       "4    [health, expert, say, sugar, good, lifestyle, ]  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = CountVectorizer(analyzer=clean_text,ngram_range=(1,2))\n",
    "tfidf_vect_fit = tfidf_vect.fit(data['text'])\n",
    "tfidf_train = tfidf_vect_fit.transform(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=50.0,\n",
       "             max_doc_update_iter=100, max_iter=5, mean_change_tol=0.001,\n",
       "             n_components=3, n_jobs=1, n_topics=None, perp_tol=0.1,\n",
       "             random_state=0, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=3, max_iter=5,\n",
    "                                learning_method='online', learning_offset=50.,\n",
    "                                random_state=0)\n",
    "lda.fit(tfidf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      " good increased\n",
      "Topic 1:\n",
      "father sister sugar\n",
      "Topic 2:\n",
      "lot dance spends\n"
     ]
    }
   ],
   "source": [
    "display_topics(lda, tfidf_vect_fit.get_feature_names(), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rec.autos' 'comp.sys.mac.hardware' 'rec.motorcycles' 'misc.forsale'\n",
      " 'comp.os.ms-windows.misc' 'alt.atheism' 'comp.graphics'\n",
      " 'rec.sport.baseball' 'rec.sport.hockey' 'sci.electronics' 'sci.space'\n",
      " 'talk.politics.misc' 'sci.med' 'talk.politics.mideast'\n",
      " 'soc.religion.christian' 'comp.windows.x' 'comp.sys.ibm.pc.hardware'\n",
      " 'talk.politics.guns' 'talk.religion.misc' 'sci.crypt']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>From: irwin@cmptrc.lonestar.org (Irwin Arnstei...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>From: tchen@magnus.acs.ohio-state.edu (Tsung-K...</td>\n",
       "      <td>6</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>From: dabl2@nlm.nih.gov (Don A.B. Lindbergh)\\n...</td>\n",
       "      <td>2</td>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  target  \\\n",
       "0     From: lerxst@wam.umd.edu (where's my thing)\\nS...       7   \n",
       "1     From: guykuo@carson.u.washington.edu (Guy Kuo)...       4   \n",
       "10    From: irwin@cmptrc.lonestar.org (Irwin Arnstei...       8   \n",
       "100   From: tchen@magnus.acs.ohio-state.edu (Tsung-K...       6   \n",
       "1000  From: dabl2@nlm.nih.gov (Don A.B. Lindbergh)\\n...       2   \n",
       "\n",
       "                 target_names  \n",
       "0                   rec.autos  \n",
       "1       comp.sys.mac.hardware  \n",
       "10            rec.motorcycles  \n",
       "100              misc.forsale  \n",
       "1000  comp.os.ms-windows.misc  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
    "print(df.target_names.unique())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=standardize_text(df,'content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>from lerxst (wheres my thing) subject what car...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>from guykuo (guy kuo) subject si clock poll fi...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>from irwin (irwin arnstein) subject re recomme...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>from tchen (tsung kun chen) subject software f...</td>\n",
       "      <td>6</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>from dabl2 (don a b lindbergh) subject diamond...</td>\n",
       "      <td>2</td>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  target  \\\n",
       "0     from lerxst (wheres my thing) subject what car...       7   \n",
       "1     from guykuo (guy kuo) subject si clock poll fi...       4   \n",
       "10    from irwin (irwin arnstein) subject re recomme...       8   \n",
       "100   from tchen (tsung kun chen) subject software f...       6   \n",
       "1000  from dabl2 (don a b lindbergh) subject diamond...       2   \n",
       "\n",
       "                 target_names  \n",
       "0                   rec.autos  \n",
       "1       comp.sys.mac.hardware  \n",
       "10            rec.motorcycles  \n",
       "100              misc.forsale  \n",
       "1000  comp.os.ms-windows.misc  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['body'] = df['content'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>from lerxst (wheres my thing) subject what car...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>[lerxst, wheres, thing, subject, car, nntp, po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>from guykuo (guy kuo) subject si clock poll fi...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>[guykuo, guy, kuo, subject, si, clock, poll, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>from irwin (irwin arnstein) subject re recomme...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>[irwin, irwin, arnstein, subject, recommendati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>from tchen (tsung kun chen) subject software f...</td>\n",
       "      <td>6</td>\n",
       "      <td>misc.forsale</td>\n",
       "      <td>[tchen, tsung, kun, chen, subject, software, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>from dabl2 (don a b lindbergh) subject diamond...</td>\n",
       "      <td>2</td>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "      <td>[dabl2, b, lindbergh, subject, diamond, ss24x,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  target  \\\n",
       "0     from lerxst (wheres my thing) subject what car...       7   \n",
       "1     from guykuo (guy kuo) subject si clock poll fi...       4   \n",
       "10    from irwin (irwin arnstein) subject re recomme...       8   \n",
       "100   from tchen (tsung kun chen) subject software f...       6   \n",
       "1000  from dabl2 (don a b lindbergh) subject diamond...       2   \n",
       "\n",
       "                 target_names  \\\n",
       "0                   rec.autos   \n",
       "1       comp.sys.mac.hardware   \n",
       "10            rec.motorcycles   \n",
       "100              misc.forsale   \n",
       "1000  comp.os.ms-windows.misc   \n",
       "\n",
       "                                                   body  \n",
       "0     [lerxst, wheres, thing, subject, car, nntp, po...  \n",
       "1     [guykuo, guy, kuo, subject, si, clock, poll, f...  \n",
       "10    [irwin, irwin, arnstein, subject, recommendati...  \n",
       "100   [tchen, tsung, kun, chen, subject, software, f...  \n",
       "1000  [dabl2, b, lindbergh, subject, diamond, ss24x,...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshat\\Anaconda3\\lib\\site-packages\\gensim\\models\\phrases.py:431: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.interfaces.TransformedCorpus object at 0x0000000029616A90>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = df.body.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshat\\Anaconda3\\lib\\site-packages\\gensim\\models\\phrases.py:431: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.interfaces.TransformedCorpus object at 0x0000000029616828>\n"
     ]
    }
   ],
   "source": [
    "bigram = gensim.models.Phrases(data, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data], threshold=100)  \n",
    "\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_big=make_bigrams_bigrams(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(data_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [id2word.doc2bow(text) for text in data_big]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 2), (1, 1), (2, 1), (3, 1), (4, 5), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 2), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 2), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1)]]\n"
     ]
    }
   ],
   "source": [
    "id2word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.035*\"max\" + 0.015*\"card\" + 0.013*\"system\" + 0.012*\"drive\" + 0.009*\"software\" + 0.008*\"use\" + 0.007*\"standard\" + 0.007*\"info\" + 0.007*\"available\" + 0.006*\"help\"'), (1, '0.018*\"would\" + 0.016*\"one\" + 0.012*\"dont\" + 0.010*\"time\" + 0.010*\"know\" + 0.009*\"like\" + 0.008*\"think\" + 0.008*\"people\" + 0.007*\"writes\" + 0.007*\"well\"'), (2, '0.023*\"god\" + 0.020*\"jesus\" + 0.015*\"christian\" + 0.009*\"life\" + 0.007*\"word\" + 0.007*\"book\" + 0.006*\"believe\" + 0.006*\"law\" + 0.006*\"bible\" + 0.006*\"belief\"'), (3, '0.123*\"q\" + 0.074*\"mr_stephanopoulos\" + 0.018*\"r\" + 0.013*\"gr\" + 0.010*\"cub_suck\" + 0.008*\"4m\" + 0.008*\"anger\" + 0.008*\"h\" + 0.007*\"l\" + 0.006*\"postscript\"'), (4, '0.030*\"00\" + 0.026*\"26\" + 0.022*\"ca\" + 0.019*\"religion\" + 0.012*\"king\" + 0.011*\"34\" + 0.009*\"hour\" + 0.008*\"directory\" + 0.008*\"mission\" + 0.008*\"st\"'), (5, '0.019*\"game\" + 0.017*\"team\" + 0.014*\"year\" + 0.010*\"player\" + 0.008*\"win\" + 0.008*\"play\" + 0.007*\"season\" + 0.007*\"jew\" + 0.006*\"first\" + 0.005*\"nhl\"'), (6, '0.022*\"car\" + 0.018*\"gun\" + 0.010*\"bike\" + 0.006*\"road\" + 0.005*\"mile\" + 0.005*\"owner\" + 0.005*\"edge\" + 0.005*\"couldnt\" + 0.005*\"dod\" + 0.004*\"weapon\"'), (7, '0.012*\"goal\" + 0.011*\"blue\" + 0.011*\"386\" + 0.010*\"normal\" + 0.010*\"33\" + 0.009*\"37\" + 0.009*\"canadian\" + 0.009*\"van\" + 0.009*\"hockey_league\" + 0.009*\"wing\"'), (8, '0.065*\"x\" + 0.045*\"file\" + 0.038*\"c\" + 0.016*\"graphic\" + 0.015*\"monitor\" + 0.011*\"bus\" + 0.011*\"specifically\" + 0.010*\"server\" + 0.010*\"xfree86\" + 0.008*\"missed\"'), (9, '0.029*\"armenian\" + 0.010*\"computer_science\" + 0.008*\"turkish\" + 0.006*\"peace\" + 0.006*\"doctor\" + 0.006*\"blood\" + 0.006*\"greek\" + 0.006*\"turk\" + 0.006*\"chief\" + 0.005*\"girl\"'), (10, '0.016*\"government\" + 0.014*\"state\" + 0.013*\"israel\" + 0.013*\"law\" + 0.012*\"right\" + 0.009*\"israeli\" + 0.008*\"american\" + 0.007*\"country\" + 0.006*\"arab\" + 0.005*\"military\"'), (11, '0.074*\"1\" + 0.071*\"2\" + 0.044*\"3\" + 0.037*\"4\" + 0.033*\"5\" + 0.025*\"7\" + 0.022*\"6\" + 0.021*\"8\" + 0.016*\"10\" + 0.015*\"9\"'), (12, '0.028*\"window\" + 0.016*\"use\" + 0.010*\"program\" + 0.009*\"using\" + 0.009*\"page\" + 0.008*\"application\" + 0.008*\"version\" + 0.008*\"code\" + 0.008*\"source\" + 0.007*\"user\"'), (13, '0.016*\"key\" + 0.013*\"president\" + 0.011*\"system\" + 0.008*\"hell\" + 0.007*\"theyre\" + 0.007*\"use\" + 0.007*\"public\" + 0.007*\"encryption\" + 0.006*\"technology\" + 0.006*\"government\"'), (14, '0.199*\"0\" + 0.045*\"1\" + 0.017*\"la\" + 0.013*\"40\" + 0.010*\"2\" + 0.009*\"nj\" + 0.009*\"pt_pt\" + 0.009*\"z\" + 0.009*\"38\" + 0.009*\"31\"'), (15, '0.694*\"ax\" + 0.011*\"g9v_g9v\" + 0.008*\"q\" + 0.007*\"p\" + 0.006*\"7\" + 0.006*\"3\" + 0.006*\"circuit\" + 0.004*\"9\" + 0.003*\"q3\" + 0.003*\"minnesota\"'), (16, '0.026*\"space\" + 0.007*\"project\" + 0.007*\"option\" + 0.007*\"cost\" + 0.006*\"law_enforcement\" + 0.005*\"science\" + 0.005*\"development\" + 0.005*\"earth\" + 0.005*\"research\" + 0.005*\"nasa\"'), (17, '0.068*\"line\" + 0.065*\"subject\" + 0.062*\"organization\" + 0.029*\"nntp_posting\" + 0.025*\"university\" + 0.025*\"writes\" + 0.024*\"host\" + 0.022*\"article\" + 0.015*\"reply\" + 0.013*\"anyone\"'), (18, '0.032*\"n\" + 0.026*\"k\" + 0.023*\"g\" + 0.022*\"w\" + 0.018*\"v\" + 0.011*\"u\" + 0.009*\"f\" + 0.008*\"b\" + 0.008*\"7\" + 0.008*\"6\"'), (19, '0.009*\"p\" + 0.009*\"information\" + 0.009*\"hockey\" + 0.008*\"center\" + 0.007*\"1993\" + 0.007*\"e_mail\" + 0.007*\"robert\" + 0.007*\"canada\" + 0.006*\"contact\" + 0.006*\"29\"')]\n"
     ]
    }
   ],
   "source": [
    "print(lda_model.print_topics())\n",
    "#doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.interfaces.TransformedCorpus at 0x29616f60>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
