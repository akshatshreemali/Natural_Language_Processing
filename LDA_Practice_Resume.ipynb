{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string,re,nltk\n",
    "from nltk import WordNetLemmatizer\n",
    "stopwords=nltk.corpus.stopwords.words('english')\n",
    "wn=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"C:/Users/Akshat/Desktop/t.txt\") as file:\n",
    "    lines = []\n",
    "    for line in file:\n",
    "        # The rstrip method gets rid of the \"\\n\" at the end of each line\n",
    "        lines.append(line.rstrip().split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/Akshat/Desktop/t.txt', 'r') as myfile:\n",
    "    data=myfile.read().replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standardize_text(text_field):\n",
    "    text_field = text_field.replace(r\"http\\S+\", \"\")\n",
    "    text_field = text_field.replace(r\"http\", \"\")\n",
    "    text_field = text_field.replace(r\"@\\S+\", \"\")\n",
    "    text_field = text_field.replace(r\"[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]\", \" \")\n",
    "    text_field = text_field.replace(r\"@\", \"at\")\n",
    "    text_field = text_field.lower()\n",
    "    text_field = text_field.replace('\\s+', ' ')\n",
    "    text_field = text_field.replace(\"\\'\", \"\")\n",
    "    return text_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=standardize_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = \"\".join([word for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [wn.lemmatize(word) for word in tokens if word not in stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string,re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=clean_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation,NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=50.0,\n",
       "             max_doc_update_iter=100, max_iter=5, mean_change_tol=0.001,\n",
       "             n_components=5, n_jobs=1, n_topics=None, perp_tol=0.1,\n",
       "             random_state=0, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Initialize variables\n",
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_topics = 5\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(a)\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, max_iter=5,\n",
    "                                learning_method='online', learning_offset=50.,\n",
    "                                random_state=0)\n",
    "lda.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words=10):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print (\"Topic %d:\" % (topic_idx))\n",
    "        print (\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "data analytics created 2016 2014 trend software automated reporting dashboard\n",
      "Topic 1:\n",
      "analysis reporting public proof decrease jul hour science spark created\n",
      "Topic 2:\n",
      "model resulting business rate jun cleaning insurance dec response tool\n",
      "Topic 3:\n",
      "project microstrategy warehouse process intelligence gathering oracle present science rate\n",
      "Topic 4:\n",
      "mstr complaint algorithm new concept modeling research sql intelligence jul\n",
      "Topic 5:\n",
      "using time 2015 july senior team business jul response trend\n",
      "Topic 6:\n",
      "resolution client spark presales research 2015 new hour time resulting\n",
      "Topic 7:\n",
      "sql team organization apache building dashboard 2018 automated hr business\n",
      "Topic 8:\n",
      "creating application custom sap 2018 present warehouse software trend cleaning\n",
      "Topic 9:\n",
      "python server learning assistant hr resolution tool using data spark\n"
     ]
    }
   ],
   "source": [
    "display_topics(lda, tf_vectorizer.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "data using team reporting client 2016 july 2014 response trend\n",
      "Topic 1:\n",
      "analysis time complaint created spark apache public proof decrease senior\n",
      "Topic 2:\n",
      "model 2015 resulting rate business jun new application insurance dec\n",
      "Topic 3:\n",
      "project organization microstrategy creating resolution warehouse process intelligence cleaning presales\n",
      "Topic 4:\n",
      "python sql mstr server analytics algorithm concept jul hour modeling\n"
     ]
    }
   ],
   "source": [
    "display_topics(lda, tf_vectorizer.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(a)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshat\\Anaconda3\\lib\\site-packages\\gensim\\models\\phrases.py:431: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "bigram = gensim.models.Phrases(a, min_count=5, threshold=10) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[a], threshold=100)  \n",
    "\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[texts]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[]]\n"
     ]
    }
   ],
   "source": [
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words= make_bigrams(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [id2word.doc2bow(text) for text in data_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=10, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data using sql python reporting\n",
      "data using python sql team\n",
      "data using python sql reporting\n",
      "data using team sql python\n",
      "data using python analysis sql\n",
      "data using python sql analysis\n",
      "data using python sql resulting\n",
      "data using python sql business\n",
      "data using python sql team\n",
      "data using python sql team\n"
     ]
    }
   ],
   "source": [
    "x=lda_model.show_topics(num_topics=10, num_words=5,formatted=False)\n",
    "topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in x]\n",
    "\n",
    "# #Below Code Prints Topics and Words\n",
    "# for topic,words in topics_words:\n",
    "#     print(str(topic)+ \"::\"+ str(words))\n",
    "# print()\n",
    "\n",
    "#Below Code Prints Only Words \n",
    "for topic,words in topics_words:\n",
    "    print(\" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.004*\"data\" + 0.004*\"using\" + 0.004*\"python\" + 0.004*\"sql\" + '\n",
      "  '0.003*\"reporting\" + 0.003*\"analysis\" + 0.003*\"team\" + 0.003*\"2015\" + '\n",
      "  '0.003*\"server\" + 0.003*\"model\"'),\n",
      " (1,\n",
      "  '0.004*\"data\" + 0.004*\"using\" + 0.004*\"python\" + 0.003*\"sql\" + 0.003*\"team\" '\n",
      "  '+ 0.003*\"reporting\" + 0.003*\"mstr\" + 0.003*\"analysis\" + 0.003*\"business\" + '\n",
      "  '0.003*\"server\"'),\n",
      " (2,\n",
      "  '0.004*\"data\" + 0.004*\"using\" + 0.003*\"python\" + 0.003*\"sql\" + '\n",
      "  '0.003*\"reporting\" + 0.003*\"analysis\" + 0.003*\"team\" + 0.003*\"model\" + '\n",
      "  '0.003*\"resulting\" + 0.003*\"time\"'),\n",
      " (3,\n",
      "  '0.003*\"data\" + 0.003*\"using\" + 0.003*\"python\" + 0.003*\"team\" + 0.003*\"sql\" '\n",
      "  '+ 0.003*\"analysis\" + 0.003*\"server\" + 0.003*\"business\" + 0.003*\"time\" + '\n",
      "  '0.003*\"reporting\"'),\n",
      " (4,\n",
      "  '0.004*\"data\" + 0.004*\"using\" + 0.003*\"python\" + 0.003*\"analysis\" + '\n",
      "  '0.003*\"sql\" + 0.003*\"team\" + 0.003*\"2015\" + 0.003*\"reporting\" + '\n",
      "  '0.003*\"project\" + 0.003*\"business\"'),\n",
      " (5,\n",
      "  '0.042*\"data\" + 0.030*\"using\" + 0.021*\"python\" + 0.019*\"sql\" + '\n",
      "  '0.013*\"analysis\" + 0.013*\"team\" + 0.011*\"reporting\" + 0.009*\"resulting\" + '\n",
      "  '0.009*\"time\" + 0.009*\"model\"'),\n",
      " (6,\n",
      "  '0.004*\"data\" + 0.004*\"using\" + 0.004*\"python\" + 0.003*\"sql\" + '\n",
      "  '0.003*\"resulting\" + 0.003*\"reporting\" + 0.003*\"team\" + 0.003*\"server\" + '\n",
      "  '0.003*\"model\" + 0.003*\"2015\"'),\n",
      " (7,\n",
      "  '0.003*\"data\" + 0.003*\"using\" + 0.003*\"python\" + 0.003*\"sql\" + '\n",
      "  '0.003*\"business\" + 0.003*\"model\" + 0.003*\"analysis\" + 0.003*\"reporting\" + '\n",
      "  '0.003*\"team\" + 0.003*\"server\"'),\n",
      " (8,\n",
      "  '0.004*\"data\" + 0.004*\"using\" + 0.004*\"python\" + 0.003*\"sql\" + 0.003*\"team\" '\n",
      "  '+ 0.003*\"business\" + 0.003*\"mstr\" + 0.003*\"analysis\" + 0.003*\"model\" + '\n",
      "  '0.003*\"2015\"'),\n",
      " (9,\n",
      "  '0.004*\"data\" + 0.004*\"using\" + 0.004*\"python\" + 0.004*\"sql\" + 0.003*\"team\" '\n",
      "  '+ 0.003*\"analysis\" + 0.003*\"reporting\" + 0.003*\"mstr\" + 0.003*\"business\" + '\n",
      "  '0.003*\"creating\"'),\n",
      " (10,\n",
      "  '0.004*\"using\" + 0.003*\"data\" + 0.003*\"python\" + 0.003*\"sql\" + '\n",
      "  '0.003*\"analysis\" + 0.003*\"team\" + 0.003*\"reporting\" + 0.003*\"server\" + '\n",
      "  '0.003*\"mstr\" + 0.003*\"business\"'),\n",
      " (11,\n",
      "  '0.004*\"data\" + 0.004*\"sql\" + 0.004*\"using\" + 0.004*\"python\" + '\n",
      "  '0.003*\"analysis\" + 0.003*\"team\" + 0.003*\"mstr\" + 0.003*\"reporting\" + '\n",
      "  '0.003*\"model\" + 0.003*\"server\"'),\n",
      " (12,\n",
      "  '0.004*\"data\" + 0.004*\"using\" + 0.004*\"python\" + 0.004*\"sql\" + 0.003*\"team\" '\n",
      "  '+ 0.003*\"reporting\" + 0.003*\"business\" + 0.003*\"analysis\" + 0.003*\"2015\" + '\n",
      "  '0.003*\"time\"'),\n",
      " (13,\n",
      "  '0.003*\"data\" + 0.003*\"using\" + 0.003*\"python\" + 0.003*\"sql\" + 0.003*\"team\" '\n",
      "  '+ 0.003*\"server\" + 0.003*\"analysis\" + 0.003*\"project\" + 0.003*\"reporting\" + '\n",
      "  '0.003*\"mstr\"'),\n",
      " (14,\n",
      "  '0.003*\"data\" + 0.003*\"using\" + 0.003*\"sql\" + 0.003*\"python\" + 0.003*\"team\" '\n",
      "  '+ 0.003*\"analysis\" + 0.003*\"business\" + 0.003*\"server\" + 0.003*\"reporting\" '\n",
      "  '+ 0.003*\"model\"'),\n",
      " (15,\n",
      "  '0.004*\"data\" + 0.004*\"using\" + 0.004*\"python\" + 0.003*\"sql\" + 0.003*\"team\" '\n",
      "  '+ 0.003*\"reporting\" + 0.003*\"analysis\" + 0.003*\"2015\" + 0.003*\"resulting\" + '\n",
      "  '0.003*\"time\"'),\n",
      " (16,\n",
      "  '0.003*\"data\" + 0.003*\"using\" + 0.003*\"python\" + 0.003*\"sql\" + 0.003*\"team\" '\n",
      "  '+ 0.003*\"analysis\" + 0.003*\"reporting\" + 0.003*\"resulting\" + '\n",
      "  '0.003*\"business\" + 0.003*\"model\"'),\n",
      " (17,\n",
      "  '0.003*\"data\" + 0.003*\"using\" + 0.003*\"python\" + 0.003*\"sql\" + '\n",
      "  '0.003*\"analysis\" + 0.003*\"reporting\" + 0.003*\"team\" + 0.003*\"resulting\" + '\n",
      "  '0.003*\"model\" + 0.003*\"time\"'),\n",
      " (18,\n",
      "  '0.004*\"data\" + 0.004*\"using\" + 0.003*\"python\" + 0.003*\"sql\" + 0.003*\"2015\" '\n",
      "  '+ 0.003*\"analysis\" + 0.003*\"reporting\" + 0.003*\"team\" + 0.003*\"mstr\" + '\n",
      "  '0.003*\"model\"'),\n",
      " (19,\n",
      "  '0.003*\"data\" + 0.003*\"using\" + 0.003*\"sql\" + 0.003*\"python\" + '\n",
      "  '0.003*\"analysis\" + 0.003*\"reporting\" + 0.003*\"model\" + 0.003*\"team\" + '\n",
      "  '0.003*\"resulting\" + 0.003*\"business\"')]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(lda_model.print_topics())\n",
    "#doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mallet_path = 'C:/Users/Akshat/Downloads/mallet-2.0.8/mallet-2.0.8/bin/mallet' # update this path\n",
    "# ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=10, id2word=id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -7.01821547438\n",
      "\n",
      "Coherence Score:  0.244629476127\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_words, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
